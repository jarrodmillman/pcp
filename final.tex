\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb, graphicx, subfigure}
\usepackage{diagbox}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage[round]{natbib}

% Commands for annotating the docs with fixme and inter-author notes.  See
% below for how to disable these.
%
% Define a \fixme command to mark visually things needing fixing in the draft,
% as well as similar commands for each author to leave initialed special
% comments in the document.
% For final printing or to simply disable these bright warnings, copy
% (there's a target macros_off' in the makefile that does this) the file
% macros_off.tex to macros.tex
\newcommand{\fixme}[1] { \textcolor{red} {
{\fbox{ {\bf Fix:} \ensuremath{\blacktriangleright }} {\bf #1}
\fbox{\ensuremath{\blacktriangleleft} } } } }



\setlength{\oddsidemargin}{.25in}
\setlength{\evensidemargin}{.25in}
\setlength{\textwidth}{6in}
\setlength{\topmargin}{-0.4in}
\setlength{\textheight}{8.5in}

\newcommand{\heading}[6]{
  \renewcommand{\thepage}{\arabic{page}}
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { \textbf{#2} \hfill #3 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #6  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\large \hfill ``On Dinur's Proof of the PCP Theorem'' \hfill} }
      \vspace{3mm}
      \hbox to 5.78in { \textit{Instructor: #4 \hfill #5} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{problem}[theorem]{Computational Problem}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

\newenvironment{proof}{\noindent{\bf Proof:} \hspace*{1mm}}{
	\hspace*{\fill} $\Box$ }
\newenvironment{proof_of}[1]{\noindent {\bf Proof of #1:}
	\hspace*{1mm}}{\hspace*{\fill} $\Box$ }
\newenvironment{proof_idea}{\noindent {\bf Proof Idea:}
	\hspace*{1mm}}{\hspace*{\fill} $\Box$ }
\newenvironment{proof_claim}{\begin{quotation} \noindent Proof: \hspace*{1mm}}{
	\hspace*{\fill} $\diamond$ \end{quotation}}

\newenvironment{algorithm}{\noindent{\bf Algorithm:} \hspace*{1mm}}{
	\hspace*{\fill} $\Box$ }
\newenvironment{strategy}{\noindent{\bf Strategy:} \hspace*{1mm}}{
	\hspace*{\fill} $\Box$ }

\newcommand{\problemset}[3]{\heading{}{CS276: Cryptography}{#2}{Alessandro Chiesa}{#3}{Final Project}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PLEASE MODIFY THESE FIELDS AS APPROPRIATE
\newcommand{\problemsetnum}{4}          % problem set number
\newcommand{\duedate}{December 3, 2017}  % problem set deadline
\newcommand{\studentname}{K. Jarrod Millman}    % full name of student (i.e., you)
% PUT HERE ANY PACKAGES, MACROS, etc., ADDED BY YOU

%-----------------------------------------------------------------------------
% Special-purpose color definitions (dark enough to print OK in black and white)
\usepackage{color}

% A few colors to replace the defaults for certain link types
\definecolor{orange}{cmyk}{0,0.4,0.8,0.2}
\definecolor{darkorange}{rgb}{.71,0.21,0.01}
\definecolor{darkgreen}{rgb}{.12,.54,.11}

%-----------------------------------------------------------------------------
% The hyperref package gives us a pdf with properly built
% internal navigation ('pdf bookmarks' for the table of contents,
% internal cross-reference links, web links for URLs, etc.)
\usepackage{hyperref}

\hypersetup{pdftex,  % needed for pdflatex
  breaklinks=true,  % so long urls are correctly broken across lines
  colorlinks=true,
  urlcolor=blue,
  linkcolor=darkorange,
  citecolor=darkgreen,
  }

%%%%%%%%%%%%%%%%%%%%%%% general useful macros
\usepackage{mathtools}
\newcommand{\N}{{\mathbf N}}
\newcommand{\Z}{{\mathbf Z}}
\newcommand{\F}{{\mathbf F}}
\newcommand{\Q}{{\mathbf Q}}
\newcommand{\R}{{\mathbf R}}
\newcommand{\Time}{\operatorname{time}}
\newcommand{\poly}{{\mathrm{poly}}}
\newcommand{\polylog}{{\mathrm{polylog}}}
\newcommand{\loglog}{{\mathop{\mathrm{loglog}}}}
\newcommand{\E}{\operatorname{E}}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand{\comp}[1]{\overline{#1}}



\newcommand{\bits}{\{0,1\}}
\newcommand{\class}[1]{\mathbf{#1}}
\newcommand{\coclass}[1]{\mathbf{co\mbox{-}#1}} % and their complements
\newcommand{\BPP}{\class{BPP}}
\newcommand{\NP}{\class{NP}}
\newcommand{\PCP}{\class{PCP}}
\newcommand{\coNP}{\coclass{NP}}
\newcommand{\RP}{\class{RP}}
\newcommand{\coRP}{\coclass{RP}}
\newcommand{\ZPP}{\class{ZPP}}
\newcommand{\RNC}{\class{RNC}}
\newcommand{\RL}{\class{RL}}
\renewcommand{\L}{\class{L}}
\newcommand{\coRL}{\coclass{RL}}
\newcommand{\IP}{\class{IP}}
\newcommand{\AM}{\class{AM}}
\newcommand{\MA}{\class{MA}}
\renewcommand{\P}{\class{P}}
\newcommand\prBPP{\class{prBPP}}
\newcommand\prRP{\class{prRP}}
\newcommand\prP{\class{prP}}
\newcommand{\Ppoly}{\class{P/poly}}
\newcommand{\DTIME}{\class{DTIME}}
\newcommand{\ETIME}{\class{E}}
\newcommand{\BPTIME}{\class{BPTIME}}
\newcommand{\EXP}{\class{EXP}}
\newcommand{\SUBEXP}{\class{SUBEXP}}
\newcommand{\qP}{\class{\tilde{P}}}
\newcommand{\PH}{\class{PH}}
\newcommand{\NC}{\class{NC}}
\newcommand{\PSPACE}{\class{PSPACE}}
\newcommand{\quasiP}{\class{\tilde{P}}}
\newcommand{\BPAC}{\class{BPAC_0}}
\newcommand{\qAC}{\class{\widetilde{AC}_0}}

\newcommand{\PRIMES}{\mathsf{PRIMES}}
\newcommand{\GEN}{\mathsf{GEN}}
\newcommand{\CSP}{\mathsf{CSP}}
\newcommand{\COL}{\mathsf{COL}}
\newcommand{\MAX}{\mathsf{MAX}}
\newcommand{\SAT}{\mathsf{SAT}}
\newcommand{\UNSAT}{\mathsf{UNSAT}}
\newcommand{\GAPSAT}{\mathsf{GAP\;3SAT}}

\newcommand{\opt}{{\operatorname{opt}}}
\newcommand{\prep}{{\operatorname{prep}}}
\newcommand{\cloud}{{\operatorname{cloud}}}
\newcommand{\negl}{{\mathrm{neg}}}
\newcommand{\Diam}{\mathrm{Diam}}
\newcommand{\Cut}{\mathrm{Cut}}
\newcommand{\pf}{\mathit{pf}}
\newcommand{\Col}{\mathrm{Col}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\iid}{\stackrel{\mathrm{iid}}{\sim}}
\newcommand{\eqdef}{\mathbin{\stackrel{\rm def}{=}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\problemset{\problemsetnum}{\duedate}{\studentname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\abstract{\cite{radhakrishnan2007dinur} discuss the proof by
\cite{dinur2007pcp} of the PCP theorem.
Dinur's proof roughly takes the form:
Let $G_0$ be a constraint graph encoding a $3\SAT$ instance.
Fix $t=O(1)$.
%Set $G_0=G$.
For a PCP reduction $\mathcal{P}$ (to be described) repeat the following $\log|G_0|$ times:
\begin{align*}
G_{i+1}=G_i^t \circ \mathcal{P}.
\end{align*} }

\section{Introduction}

In class, we discussed\footnote{It was lucky coincidence that the fun "advanced" topic
was succinct arguments and PCPs.}
interactive proof systems introduced by \citet*{goldwasser1989knowledge}.
In particular, we saw we could view $\NP$ as a simple proof system with a
deterministic polynomial-time verifier interacting with an all-powerful prover.
We also saw that by providing the verifier access to randomness and assuming
the existence of one-way functions, we could obtain systems with the remarkable
property of zero-knowledge.

For the final project, I investigated a related line of work involving
probabilistic proof systems.
%another line of thought developed from
%this concept of computation through interaction. 
%This line of thought begins by considering a probabilistic verifier with oracle
%access to the proof.
\citet*{feige1996interactive} showed that probabilistic proof systems
were closely related to hardness of approximations.
Building on this relationship, \citet*{arora1998probabilistic} and
\citet*{arora1998proof} proved the PCP Theorem, which shows that a
probabilistic verifier with logarithmic randomness and a constant number of
queries provides a new way of characterizing $\NP$.
The original proof was algebraic and difficult.  \cite{dinur2007pcp} provided a
relatively simple, new proof with a combinatorial flavor.

%In section~\ref{pcp}, I briefly recall the notion of an interactive proof
%system.
%Then I define probabilistically checkable proofs and formally state the PCP
%theorem.
%Next I introduce constraints satisfaction problems (CSPs) and the CSP variant
%of the PCP theorem.
%I conclude the section with a proof of the equivalence of these two theorems.
%Finally, in section~\ref{proof}, I briefly outline Dinur's proof of the PCP
%theorem.

%\section{Preliminaries}

\section{PCP Theorem}\label{pcp}

A \emph{system of logic} (or a proof system) is composed of (1) axioms
and (2) rules of derivation.
A proof of a claim consists of a sequence of sentences ending with the claim
such that each sentence is (1) an axiom or (2) may be derived according to the rules
from the previous sentences in the proof.
We desire two main properties from such a system:
\begin{itemize}[leftmargin=10em]
\item[\textbf{(Completeness)}] True claims have a proof.
\item[\textbf{(Soundness)}] False claims have no proof.
\end{itemize}

%Experience suggests that there is a difference in difficulty between
%Experience suggests that producing a proof and verifying a proof
%are distinct activities.
%Using the verifier-based definition of $\NP$, it is easy to see that
%we can characterize $\NP$ as  
%
%Interactive proof systems involve the interactions between
%two parties: an all-powerful prover $P$ and an efficient
%verifier $V$.
%The idea is that for an claim $x$, the prover $P$ provides a
%proof $\pi$ of the claim $x$ to the verifier $V$.
%More formally,\\
%\begin{definition}

From a computational perspective, a \emph{traditional proof system} for a
language $L \subseteq \bits^*$ is a deterministic, polynomial-time verifier $V$
such that for all $x \in \bits^*$ the following holds:
\begin{itemize}[leftmargin=10em]
\item[\textbf{(Completeness)}] $\;x \in\; L \;\implies\; \exists \pi \quad V(x, \pi) \text{ accepts}$.
\item[\textbf{(Soundness)}] $\;x \notin\; L \;\implies\; \forall \pi \quad V(x, \pi) \text{ rejects}$.
\end{itemize}
%\end{definition}
Imagine the verifier $V$ checking that each sentence of the proof $\pi$
is an axiom or derived from previous sentences in the proof to see how
this corresponds to a system of logic.

Since $V$ runs in polynomial time in $|x|$, we have
$|\pi| \le p(|x|)$ for some polynomial $p$.
It is clear---from the verifier-based definition of $\NP$---that traditional proof
systems are an equivalent characterization of $\NP$.
%So we may view the theory of $\NP$-completeness as providing a collection of
%equivalent systems for writing proofs. 
The PCP Theorem provides another characterization of $\NP$.
Before stating the PCP Theorem, we discuss probabilistically checkable proofs.

%...
%
%...
%
%...
%
%...
%
%...
%
%...
%
%...


\subsection{Probabilistically Checkable Proofs}

We give the verifier access to randomness and oracle access to the proof.

\begin{definition}[$(r, q)$-restricted verifier]
A probabilistic polynomial time oracle algorithm $V$ is a \emph{$(r, q)$-restricted verifier} if,
for all input $x$ of size $n$ and every proof $\pi$, $V^\pi(x)$ makes at most $q(n)$ oracle queries
to $\pi$ and uses at most $r(n)$ random bits.
\end{definition}

With these $(r, q)$-restricted verifiers, we define the following complexity classes.

\begin{definition}[PCP complexity classes]
A language $L\subseteq\bits^*$ is in $\PCP[r(n), q(n)]$ if there is a
$(r, q)$-restricted verifier $V$ such that
\begin{itemize}[leftmargin=10em]
\item[\textbf{(Completeness)}] $\;x \in\; L \;\implies\; \exists \pi \quad \Pr[V^\pi(x) \text{ accepts}] = 1$.
\item[\textbf{(Soundness)}] $\;x \notin\; L \;\implies\; \forall \pi \quad \Pr[V^\pi(x) \text{ accepts}] \le 1/2$.
\end{itemize}
\end{definition}
We use the notation $\PCP_s[r(n), q(n)]$ to indicate the \emph{soundness error} is $s$ and not $1/2$.

To get a sense of how these classes relate to more standard complexity classes,
note that setting the parameters to $0$ yields the following trivial equivalences:
\begin{align*}
\P &= \PCP[0, 0] \\
\NP &= \PCP[0, \poly(n)] \\
\coRP &= \PCP[\poly(n), 0].
\end{align*}
Since we can derandomize (\emph{via} enumeration) any probabilistic polynomial-time algorithm
using $O(\log n)$ random bits, we have
$$
\PCP[O(\log n), O(1)] \subseteq \NP.
$$
Surprisingly, the PCP Theorem gives us the converse as well.

\begin{theorem}[PCP Theorem]\label{pcp}
$$
\NP = \PCP[O(\log n), O(1)]
$$
\end{theorem}

By the above remark, it suffices to show that
$$
\NP \subseteq \PCP[O(\log n), O(1)]
$$
to prove the PCP theorem.
To outline of Dinur's proof of this fact, we first
discuss hardness of approximation for constraint satisfaction.

\subsection{PCPs and Approximations}

%To see the relation between PCPs and approximation let's consider the
%following problem.

Let $\mathcal{C} = \{c_1, c_2, \dots, c_m\}$ be a collection of constraints on
variables $x_1, x_2, \dots, x_n$ taking values from some alphabet $\Sigma$.
If there is an assignment of values to the variables satisfying all the
constraints, we say $\mathcal{C}$ is \emph{satisfiable}; otherwise, we say
$\mathcal{C}$ is \emph{unsatisfiable}.
Note that if $\mathcal{C}$ is \emph{unsatisfiable}, then at least one of the
$m$ constraints must be unsatisfied no matter how we assign values to the
variables and we say $\mathcal{C}$ is \emph{$1/m$-far} from satisfiable. 

For example, consider $3\COL$ the $\NP$-hard problem of deciding whether a graph is 3-colorable.
\begin{center}
\begin{tabular}{c @{$\quad\longleftrightarrow\quad$} c}
$\CSP$ instance & $3\COL$ instance\\
\hline
variables $x_1, x_2, \dots, x_n$ & vertices $v_1, v_2, \dots, v_n$ of $G = (V, E)$\\
alphabet $\Sigma$ & colors $\{1, 2, 3\}$ \\
constraints $c_1, c_2, \dots, c_m$ & edge constraints $\{c_e \subseteq \{1, 2, 3\}^2 \;:\;\text{colors differ}\}_{e \in E}$\\
\end{tabular}
\end{center}
If a graph is not 3-colorable, then the edge constraints are $1/m$-far from satisfiable
where $m=|E|$ (since at least one edge must be monochromatic).

$\MAX$ $3\COL$ is the problem of finding a 3-coloring that minimizes the
number of monochromatic edges of a graph.
This problem is $\NP$-hard by the obvious reduction from the corresponding
$3\COL$ decision problem.
Let $\opt_{\MAX\text{ }3\COL}(G)$ denote the optimal solution to $\MAX$ $3\COL$
on input $G$.
An algorithm $A$ is an \emph{$\varepsilon$-approximation} $\MAX$ $3\COL$ algorithm
if for every graph $G$, $A(G)$ returns a 3-coloring
satisfying at least $\varepsilon \cdot \opt_{\MAX\text{ }3\COL}(G)$
edge constraints.
A natural question is whether there exist polynomial time $\varepsilon$-approximation
algorithms for $\MAX$ $3\COL$ for every $\varepsilon<1$.
Or is there a universal constant $\varepsilon_0$ such that it is
$\NP$-hard to find a 3-coloring satisfying at least $\varepsilon_0 \cdot \opt_{\MAX\text{ }3\COL}(G)$
edge constraints?

Given any two-variable constraint system (i.e., one where each
constraint involves at most two variables), we can construct a constraint graph
over the variables by creating an edge for each constraint in the natural way.

%on which values from $\Sigma$ a set of $n$ variables $V$ may take.
%Given a set of $n$ variables $V$ taking values from a set $\Sigma$,
%a system of constraints $\mathcal{C} = \{c_1, c_2, \dots, c_m\}$
%impose conditions that the variables must satisfy.


\begin{definition}[Constraint Graph] A constraint graph is a tuple
$G = (V, E, \Sigma, \mathcal{C})$ where
\begin{enumerate}
\item the ordered pair $(V, E)$ is an undirected graph\footnote{Unless stated otherwise, we allow multiple edges and self-loops.} called the underlying
  graph of $G$,
\item every vertex in $V$ takes values in the finite set $\Sigma$
  called the alphabet of $G$, and
\item each edge $e$  has a constraint $c_e \subseteq \Sigma^2$ and
  $\mathcal{C} = \{c_e\}_{e \in E}$.
\end{enumerate}
\end{definition}

An \emph{assignment} of $G$ is a function $\sigma \;:\: V \to \Sigma$.
We a say a constraint $c_e$ is satisfied by $(a, b)$ if $(a, b) \in c_e$. 
An assignment $\sigma$ satisfies $G$ if every edge $\{u, v\} \in E$
is satisfied by $(\sigma(u), \sigma(v))$.
For any assignment $\sigma$, we define
\begin{align*}
\UNSAT_\sigma(G) \;\eqdef\; \Pr_{\{u, v\} \in E} \big[(\sigma(u), \sigma(v)) \notin c_{\{u, v\}}\big] 
  \;=\; \frac{\big|\{e \in E \;:\; \sigma \text{ does not satisfy } c_e\}\big|}{|E|}
\end{align*}
and
\begin{align*}
\UNSAT(G) \;\eqdef\; \min_\sigma \UNSAT_\sigma(G)
  \;=\; \max_\varepsilon \{\varepsilon \;:\; G \text{ is } \varepsilon\text{-far from satisfied} \}.
\end{align*}
We call $\UNSAT(G)$ the \emph{unsat-value} of $G$.
% is the smallest fraction of unsatisfied
%constraints over all possible assignments
The \emph{constraint graph satisfiability problem} is to decide whether
a constraint graph admits a satisfying assignment.
%Note that the \emph{size} of a description of $G$, denoted $size(G)$, is $\Theta(|V|+|E|\cdot|\Sigma|^2)$.
Note that the \emph{size} of the input $G$ (denoted $|G|$) is $\Theta(|V|+|E|\cdot|\Sigma|^2)$.
%By reducing from graph $k$-colorability, it is easy to see that
%the constraint graph satisfiability problem is also $\NP$-hard.

%\begin{example}[Graph $k$-coloring]
%Given a graph $(V, E)$, we want to know whether it admits a $k$-coloring.
%This can be cast as a constraint graph with $(V, E)$ as the underlying
%graph, $\Sigma = \{1, 2, \dots, k\}$, and $c_{\{u, v\}} = 
%\end{example}

We now state Dinur's main theorem.

\begin{theorem}[Dinur's Main Theorem]\label{dinursthm}
For all alphabets $\Sigma$ such that $|\Sigma| = O(1)$ there exists constants $c > 0$ and
$0 < \alpha < 1$ such that for any constraint graph $G = (V, E, \Sigma, \mathcal{C})$
one can efficiently (i.e., in polynomial time) construct another constraint graph
$G' = (V', E', \Sigma_0, \mathcal{C}')$ such that
\begin{itemize}[leftmargin=10em]
%\item[\textbf{(Linear blowup)}] $size(G') \le c \cdot size(G)$ and $|\Sigma_0| = O(1)$.
\item[\textbf{(Linear blowup)}] $|G'| \le c \cdot |G|$ and $|\Sigma_0| = O(1)$.
\item[\textbf{(Completeness)}] $\UNSAT(G)=0 \implies \UNSAT(G')=0$.
\item[\textbf{(Soundness)}] $\UNSAT(G')\ge \min\{2\cdot\UNSAT(G), \alpha\}$.
\end{itemize}
\end{theorem}
In other words, this efficient construction preserves completeness, doubles
soundness, and incurs a linear blowup in the size of the problem.

We discuss Dinur's proof in the next section.
First, we see that it implies the PCP Theorem.

\begin{corollary}[PCP Theorem, Alternative Formulation]\label{corollary}
$\GAPSAT$ is $\NP$-hard.
\end{corollary}

We use the following lemma.

\begin{lemma}\label{csg-hard} It is $\NP$-hard to decide if $\UNSAT(G)=0$ given
a constraint graph satisfaction problem with $|\Sigma| = 3$.
\end{lemma}

\begin{proof}%We reduce from the $\NP$-complete problem of graph 3-coloring.
Let $G = (V,E)$ be an instance of the $\NP$-complete $3\COL$ problem.
Construct a constraint graph $G'=(V, E, \Sigma, \mathcal{C})$ with
$G$ as its underlying graph as follows:
Let the alphabet be $\Sigma = \{1, 2, 3\}$ for the 3 colors and place
inequality constraints on each edge of the graph.
Clearly, $G$ is 3-colorable exactly when $\UNSAT(G')=0$.
\end{proof}\\

\begin{proof_of}{Corollary~\ref{corollary}}
To prove that $\GAPSAT$ is $\NP$-hard, we must show that for some universal
constant $\alpha > 0$, given a set of constraints $\mathcal{C} = \{c_1, c_2, \dots, c_m\}$
each of which is a disjunction of three literals, it is $\NP$-hard to decide
whether $\UNSAT(G)=0$ or $\UNSAT(G)>\alpha$.
To do this, we reduce from the constraint graph satisfaction problem with
$|\Sigma| = 3$, which by Lemma~\ref{csg-hard} we know to be $\NP$-hard.

Let $G_0 = (V_0, E_0, \Sigma, \mathcal{C})$ be an instance of the constraint
graph satisfaction problem with $|\Sigma| = 3$.
By iteratively applying Theorem~\ref{dinursthm}, we construct a sequence
of constraint graphs $G_0, G_1, \dots, G_t$ such that $G_i$ is the constraint
graph constructed from $G_{i-1}$ for $i\ge 1$.

\fixme{until a constant fraction...see Dinur p. 13, Trevisan p. 9}
\end{proof_of}

Finally, we show that Corollary~\ref{corollary} implies $\NP \subseteq \PCP[O(\log n),O(1)]$
and thus Theorem~\ref{pcp}.\footnote{
Corollary~\ref{corollary} and Theorem~\ref{pcp} are equivalent, but given space limitations
we will prove only one of the implications.}
In the proof of Corollary~\ref{corollary}, we demonstrated a polynomial-time
Karp reduction from the constraint graph satisfaction problem with
$|\Sigma| = 3$ to $\GAPSAT$.
%Let $L$ be any language in $\NP$.
%Since $\GAPSAT$ is $\NP$-hard, there exists a polynomial-time reduction $f$
%from $L$ to $\GAPSAT$.
On input $x$, the verifier runs the reduction  to obtain a $\GAPSAT$
instance $\varphi_x$.
The prover provides %a proof $\pi : V \to \bits$, which 
a boolean assignment to the variables of $\varphi_x$ as a candidate proof $\pi$
that $\varphi_x$ is satisfiable.
The verifier randomly selects $O(1/\alpha)$ clauses of $\varphi_x$ and
checks that they are satisfied by the assignment $\pi$.
Let $m$ be the number of clauses in $\varphi_x$.
The verifier uses $O(\log m \cdot 1/\alpha) = O(|x|)$ random bits
to select $O(1/\alpha)$ clauses of $\varphi_x$ and queries
$O(1/\alpha)$ bits of $\pi$.
Clearly,
\begin{itemize}[leftmargin=10em]
\item[\textbf{(Completeness)}] $\;x \in\; L \;\implies\; \exists \pi \quad \Pr[V^\pi(x) \text{ accepts}] = 1$.
\item[\textbf{(Soundness)}] $\;x \notin\; L \;\implies\; \forall \pi \quad \Pr[V^\pi(x) \text{ accepts}] \le 1/2$.
\end{itemize}

%\subsection{Equivalence of the two notions}

\section{Dinur's Main Theorem}\label{proof}

%take a result with a small soundness gap $1 - 1/m$
%gradually amplify the soundness to get the
%desired gap while keeping the length of the proof constant.
%
%It remains to prove Theorem~\ref{dinursthm}, which we will not do.

%Given any constraint graph $G = (V, E, \Sigma, \mathcal{C})$,
Given any constraint graph $G$,
we construct another constraint graph $G'$
%\begin{align}\label{construct}
%G' = (\prep(G))^t \circ \mathcal{P}
%\end{align}
%such that $G' = (V', E', \Sigma_0, \mathcal{C}')$ for some appropriately
%choosen $t\in \N$
with three operations:
\begin{center}
\begin{tabular}{l l p{10cm}}
1. & $\boldsymbol{\prep}(G)$ & \textbf{Preprocess} returns a ``nice'' (i.e., a $d$-regular expander)
       constraint graph with the same alphabet as $G$ and roughly the same unsat-value.\\
2. & $\prep(G)^{\boldsymbol{t}}$ & \textbf{Power} returns a constraint graph with an amplified
                    unsat-value and an increased alphabet. \\
3. & $\prep(G)^t \boldsymbol{\circ \mathcal{P}}$ & \textbf{Compose} returns a constraint graph with a reduced alphabet while roughly
                   preserving the unsat-value.
\end{tabular}
\end{center}
Once we have made these three operations precise,
proving Theorem~\ref{dinursthm} (Dinur's Main Theorem)
requires showing that $G' = \prep(G)^t \circ \mathcal{P}$ is efficiently
computable, preserves completeness, doubles soundness, and only
incurs a linear blowup in the size of the problem.
%and that the following conditions hold:
%\begin{itemize}[leftmargin=10em]
%%\item[\textbf{(Linear blowup)}] $size(G') \le c \cdot size(G)$ and $|\Sigma_0| = O(1)$.
%\item[\textbf{(Linear blowup)}] $|G'| \le c \cdot |G|$ and $|\Sigma_0| = O(1)$.
%\item[\textbf{(Completeness)}] $\UNSAT(G)=0 \implies \UNSAT(G')=0$.
%\item[\textbf{(Soundness)}] $\UNSAT(G')\ge \min\{2\cdot\UNSAT(G), \alpha\}$.
%\end{itemize}
However, due to space limitations, we will only briefly highlight some
aspects of the construction and proof idea.

\subsection{Expanders}

Expanders have proven useful in many applications
and are employed in both the preprocessing $\prep(G)$ and graph powering $\prep(G)^t$ operations
of the construction.
Intuitively expanders are sparse graphs (i.e., graphs with very few edges)
which are as \emph{nearly} well connected as complete graphs (i.e., graphs with all possible edges).

Let $G = (V, E)$ be a finite, undirected, $d$-regular graph.
For any subset of vertices $S \subseteq V$,
let $e(S, \bar{S}) = |(S\times \bar{S})\cap E|$ equal the number of edges
between $S$ and its complement $\bar{S} \equiv V - S$ and
%For any $S, T \subseteq V$, let
%$G(S)$ denote the subgraph of $G$ induced by $S$ and let $e(S, T)$
%be the number of edges with one endpoint in $S$ and one endpoint
%in $T - S$.
%If $S \subseteq B \subseteq V$, then let $\overline{S}$
%denote the complement of $S$  in $V$, $\notsin$ denote  complement of
%$S$ in $B$, and $\notsout$ denote complement of $S$ not in $B$.
%Note that $\{\notsin, \notsout\}$ is a partition of $\nots$
%(i.e., $\nots = \notsin \cup \notsout$ and $\notsin \cap \notsout = \emptyset$).
let
\begin{align*}
\phi(S) \;\eqdef\; \frac{e(S, \bar{S})}{|S|} %|\{\text{edges between } S \text{ and } V - S\}|}{d\cdot |S|}
\end{align*}
be the \emph{edge expansion} of $S$ in $G$.
Informally, we say $G$ is an \emph{expander} if it has ``large'' expansion.
Clearly, the complete graph has large expansion.
Fortunately, not only do sparse (i.e., $d$-regular) expanders exist,
but we know how to efficiently construct them.
Before stating this formally, we present an alternative definition of
expansion, which will be more convenient to work with.

Let $A$ be the \emph{adjacency matrix} of $G$.
Note that $A$ is a real-valued, symmetric $n \times n$ matrix,
so it has $n$ real-valued eigenvalues $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_n$
(counting multiplicities).
Since $G$ is $d$-regular, all eigenvalues of $A$ are at most $d$ in absolute value.
It is also easy to see that $\lambda_1=d$ with associated
eigenvector $x_1 = 1/\sqrt{n}$.

\begin{definition}[Spectral Expansion]
We say $G$ is an $(n, \lambda, d)$-expander if $G$ is a $d$-regular graph
on $n$ vertices with $\lambda \ge \max \{|\lambda_i| \;:\; i \neq 1\}$
and $\lambda < d$.
\end{definition}

Roughly speaking, large edge expansion is equivalent to a large spectral gap (i.e., $d - \lambda$).

\begin{lemma}%[Cheeger's Inequality]
For any $(n, \lambda, d)$-expander with edge expansion $\phi$, the following holds
$$
\frac{\phi^2}{2d} \le d - \lambda \le 2\phi.
$$
\end{lemma}

We repeatedly rely on the existence of polynomial-time algorithms
to construct families of constant degree expanders.

\begin{lemma}[Constant-Degree Expanders]\label{expandersexist}
Universal constants $d_0 \ge 3$ and $\lambda_0<d_0$ exist such that there
is an explicitly constructable %(i.e., polynomial-time computable)
family $\{G_n\}_{n\in \N}$ of $(n, \lambda_0, d_0)$-expanders.% (e.g., see \cite*{reingold2002entropy}).
\end{lemma}

One nice aspect of the spectral definition of
expansion comes from the variational definition of the eigenvalues
of symmetric matrices given by the Courant--Fisher Theorem.
In particular, given the adjacency matrix $A$ of any $(n, \lambda, d)$-expander
and any vector $x \in \R^n$ such that $\|x\| = 1$, we have that
$$
\lambda \ge \max_{x \perp 1} \langle Ax, x\rangle. %{\substack{\|x\| =1 \\ x \perp 1}} \langle Ax, x\rangle.
$$
To gain an appreciation for how this fact is used, we state and prove a
fact we will use in the preprocessing operation.

\begin{lemma}[Union Graph]\label{union}
Let $G$ be an $(n, \lambda, d)$-expander and $H$ be an $(n, \lambda', d')$-expander.
Then the \emph{union graph} $G' = G \cup H = (V, E_G \cup E_H)$ is an
$(n, \lambda + \lambda', d+d')$-expander.
\end{lemma}

\begin{proof}
By construction $G'$ is a $(d+d')$-regular graph on $n$ vertices.
Let $A_G, A_H, A_{G'}$ be the adjacency matrices of $G, H, G'$ respectively.
%Usin basic facts about inner products 
%We get the desired spectral expansion
%as follows
For any $x \in \R^n$ such that $\|x\| = 1$ and $x \perp 1$,
\begin{align*}
\langle (A_{G'})x, x\rangle
  \;=\; \langle (A_G+A_H)x, x\rangle
  \;=\; \langle (A_G)x, x\rangle + \langle (A_H)x, x\rangle
  \;\le\; \lambda + \lambda'.% \qedhere
\end{align*}
\end{proof}

Another useful property of expanders is that random walks rapidly approach
the uniform distribution over the vertices.
Thus having hitting properties such as the following lemma. 

%The \emph{expansion} of $G$ is
%\begin{align*}
%\phi(G) \eqdef \min_{\substack{S \subseteq V \\ 0 < |S| \le \frac{|V|}{2}}} \phi(S).
%\end{align*}

\begin{lemma}[Hitting Property of Expander Walks]
If $G$ is a $(n, \lambda, d)$-expander, then for any subset of edges $F \subset E$
of density $\mu$, the probability that a random walk starting from a random edge
in $F$ takes its $i+1$st step in $F$ is at most
$$
\mu + \left(\frac{|\lambda|}{d}\right)^i.
$$
\end{lemma}

Since $|\lambda|<d$, this probability is ``nearly equal'' to the density of
$F$ in $E$ for large $i$.

\subsection{Graph Operations}

To outline how Dinur's transformation
\begin{align*}
\prep(G)^t \circ \mathcal{P} \;:\; G \mapsto G'
\end{align*}
works, we briefly discuss (without proof) the three composed operations in her reduction:
$$
\underbrace{G \mapsto H}_\text{preprocess} \quad\text{then}\quad
\underbrace{H \mapsto H^t}_\text{power} \quad\text{then}\quad
\underbrace{H^t \mapsto G'}_\text{compose}.
$$
Excluding the preprocessing step, Dinur's construction balances two
competing transformations.  The first (power) greatly amplifies
the gap between the unsat-value of satisfiable and unsatisfiable
instances at the expense of increasing the alphabet size,
while the second (compose) reduces the alphabet size while only
modestly decreasing that greatly increased gap.

As we saw in the proof of Corollary~\ref{dinursthm}, we will iteratively apply
Dinur's transformation $\log m$ times (starting from an initial constraint graph
$G_0$ with $m$ edges) to get a sequence of graphs $G_0, G_1, \dots, G_{\log m}$.
So to ensure
$$
|G_{\log m}| \le \poly(|G_0|)
$$
requires that $|G_{i+1}|$ is at most some constant factor larger
than $|G_i|$ for every $i$.

\subsubsection*{Preprocess $\boldsymbol{\prep}(G)$}

The preprocessing operation $G \mapsto H$ is performed in two steps.
The first step $G \mapsto H_0$ returns a constant-degree constraint graph $H_0$.
The second step $H_0 \mapsto H$ ensures that the constraint graph $H$
expands by superimposing a constant degree expander on $H_0$ (and adding self-loops).

\begin{enumerate}
\item \textbf{Sparsify} $G \mapsto H_0$

This degree-reduction step uses the expander replacement technique of
\cite{papadimitriou1991optimization}.
Each vertex $v$ in graph $G$ is \emph{replaced} with an $(n, \lambda_0, d_0)$-expander
$\cloud(v)$ in graph $H_0$ (by Lemma~\ref{expandersexist})
with an equality constraint for each edge in $\cloud(v)$.
For each edge $uv$ in $G$ an edge in $H_0$ (with its constraint)
connects one vertex from $\cloud(u)$ with one vertex in $\cloud(v)$.
Thus, $H_0$ is a $(d_0+1)$-regular graph on $2\cdot|E|$ vertices.
The alphabet stays the same.
Clearly, $\UNSAT(G)=0 \implies \UNSAT(H_0)=0$ and $|H_0|=O(|G|)$.
It can be shown that there exists a constant $c_0>0$ such that
$$
c_0\cdot\UNSAT(G) \le \UNSAT(H_0) \le \UNSAT(G). 
$$

\item \textbf{Expanderize} $H_0 \mapsto H$

This step returns the union of $H_0$ and a $(2\cdot|E|, \lambda_0, d_0)$-expander
as in Lemma~\ref{union}.
Thus, $H$ is a $(2\cdot|E|, \lambda_0 + d_0 + 1, 2\cdot d_0 + 1)$-expander.
Add trivial constraints (i.e., constraints which are always satisfied)
to each edge contributed by the constant degree expander.
The alphabet stays the same.
%then it is clear that 
Clearly, $\UNSAT(H_0)=0 \implies \UNSAT(H)=0$
and $|H|=O(|H_0|)=O(|G|)$.
It can be shown that there exists a constant $c_1>0$ such that
$$
c_1\cdot\UNSAT(H_0) \le \UNSAT(H) \le \UNSAT(H_0). 
$$

\end{enumerate}

\subsubsection*{Power $\prep(G)^{\boldsymbol{t}}$}

The $t$ power operation $H \mapsto H^t$ takes as input a
constraint graph $H = (V, E, \Sigma, \mathcal{C})$ whose
underlying graph is an $(n, \lambda, d)$-expander and outputs a
constraint graph $H^t = (V, E^t, \Sigma^{d^{t/2}}, \mathcal{C}^t)$
such that:
\begin{itemize}

\item
The underlying graph $(V, E^t)$ of $H^t$ is the $t$-th power of the
underlying graph $(V, E)$ of $H$.
That is, $H^t$ has the same vertex set as $H$ and we have an edge $uv$ in $H^t$
for every length $t$ walk from $u$ to $v$ in $H$.
We refer to the edges of $H^t$ as \emph{paths} and the edges of $H$ as \emph{edges}.

\item
Let $d_H : V \times V \to \N$ be the shortest path metric on $H$.
Assignments $\sigma^t \;:\; V \to \Sigma^{d^{t/2}}$ to a vertex $v$ in $H^t$
corresponds to assigning a value from $\Sigma$ to all vertices in the $t/2$-ball\footnote{
Since $H$ is $d$-regular, no vertex has more than $d^{t/2}$ neighbors in the
$t/2$-ball around it.}
in $d_H$ around $v$.
We say an assignment $\sigma^t(v)$ to a vertex $v$ in $H^t$ is its opinion
about what values are assigned to all the vertices in the $t/2$-ball in $d_H$
around it in $H$.
For each vertex $u$ in the $t/2$-ball in $d_H$ around $v$, we say $\sigma^t(v)_u$ is
$v$'s opinion about $u$'s assignment in $H$. 

\item
For each edge $uv$ in $H^t$ the edge constaint $c_{uv}^t$ is satisfied
exactly when the opinions of $u$ and $v$ are consistent with an
assignment $\sigma \;:\; V \to \Sigma$ satisfying all constraints induced by
$u$, $v$, and their neighbors.

\end{itemize}

The powering operation $H \mapsto H^t$ amplifies the gap between the
unsat-value of satisfiable and unsatisfiable instance.

critical step and the main novelty

main lemma

\begin{lemma}[Amplification Lemma]
Fix $\lambda < d$ and $|\Sigma|$.
For all $t \in \N$ and for every $d$-regular constraint graph $H$ with
spectral expansion $\lambda$, there exists a constant $c$ depending
on $\lambda, d,$ and $|\Sigma|$ such that
$$
\UNSAT(H^t) \ge c\cdot\sqrt{t}\cdot\min\{\UNSAT(H), \frac{1}{t}\}.
$$
\end{lemma}

\begin{proof_idea}
error reduction
\end{proof_idea}

\subsubsection*{Compose $\prep(G)^t \boldsymbol{\circ \mathcal{P}}$}

Lastly, the compose operation $H^t \mapsto G'$ shrinks the alphabet size ...

alphabet-reduction

\newpage

\bibliographystyle{plainnat}
\bibliography{final}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
